[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "People Analytics Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nExpediting Exploratory Data Analysis\n\n\n\n\n\n\n\nPPSR\n\n\nCorrelation Funnel\n\n\nDataExplorer\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2023\n\n\nAdam D McKinnon\n\n\n\n\n\n\n  \n\n\n\n\nPredicting Promotions Through Machine Learning\n\n\n\n\n\n\n\nTidymodels\n\n\nXGBoost\n\n\nR\n\n\nMachine Learning\n\n\nEmployee Promotions\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2022\n\n\nAdam D McKinnon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated assessment of employee data quality using machine learning\n\n\n\n\n\n\n\nPython\n\n\nH2o\n\n\nIsolation Forests\n\n\nMachine Learning\n\n\nData Quality\n\n\n\n\nAn automated, multi-dimensional and scalable approach to monitoring and improving employee data quality using unsupervised machine learning.\n\n\n\n\n\n\nJul 21, 2022\n\n\nAdam D McKinnon, Martha Curioni, Adam D McKinnon\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dmckinnon2023,\n  author = {Adam D McKinnon and Harlow Malloc},\n  title = {Post {With} {Code}},\n  date = {2023-01-08},\n  url = {https://www.adam-d-mckinnon.com//posts/post-with-code},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAdam D McKinnon, and Harlow Malloc. 2023. “Post With Code.”\nJanuary 8, 2023. https://www.adam-d-mckinnon.com//posts/post-with-code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is my personal blog, coming to you from Melbourne, Australia. I write about the evolving field of People Analytics, mostly through the application of the R language. On this blog site you can find my posts which provide both a philosophical perspective regarding advancements in people analytics, along with practical “How To” projects applying different methods (please learn from my mistakes!)."
  },
  {
    "objectID": "posts/2023-01-03-exploratory_analysis/index.html",
    "href": "posts/2023-01-03-exploratory_analysis/index.html",
    "title": "Expediting Exploratory Data Analysis",
    "section": "",
    "text": "Start with the required libraries, and then load some data.\n\n\nCode\n# data manipulation\nlibrary(tidyverse)\nlibrary(janitor)\n\n# Data Exploration\nlibrary(ppsr)\nlibrary(correlationfunnel)\nlibrary(DataExplorer)\n\n# Visualisation addition\nlibrary(plotly)\n\n\n# Load Data ----\npromotions_tbl <- readr::read_csv(file = \"train.csv\") %>% \n    janitor::clean_names()\n\n# reduce the dataset size\ncleaned_promotions_tbl <-\npromotions_tbl %>%\n    tidyr::drop_na() %>% \n    dplyr::mutate(\n        is_promoted = as.character(is_promoted),\n        is_promoted = if_else(is_promoted==1, \"Yes\", \"No\") %>% as.factor()\n    )\n\n\n\n\n1. Predictive Power Score\n\n\nCode\ncleaned_promotions_tbl %>%\n    select(-employee_id) %>%\n    visualize_pps(y = 'is_promoted', do_parallel = TRUE)\n\n\n\n\n\n\n\n\n\n\n2. Correlation Funnel\n\n\nCode\ncleaned_promotions_tbl %>% \n    select(-employee_id) %>% \n    binarize() %>% \n    correlate(target = is_promoted__Yes) %>% \n    plot_correlation_funnel(interactive = TRUE) %>% \n    plotly::config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n3. DataExplorer\n\n\n\n\n\n\n\nDefault Heatmap\n\n\nCode\ncorr_plot <- cleaned_promotions_tbl %>% \n    select(-employee_id) %>% \n    DataExplorer::plot_correlation(\n        theme_config = list(\n            legend.position = \"none\",\n            axis.text.x     = element_text(angle = 90)\n                )\n    )\n\n\n\n\n\n\n\nInteractive Heatmap\n\n\nCode\ncorr_plot$data$value <- round(corr_plot$data$value, digits = 2)\n\nplotly::plotly_build(corr_plot) %>% \n    plotly::layout(width = 700, height = 700) %>% \n    plotly::config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dmckinnon2023,\n  author = {Adam D McKinnon},\n  title = {Expediting {Exploratory} {Data} {Analysis}},\n  date = {2023-01-03},\n  url = {https://www.adam-d-mckinnon.com//posts/2023-01-03-exploratory_analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAdam D McKinnon. 2023. “Expediting Exploratory Data\nAnalysis.” January 3, 2023. https://www.adam-d-mckinnon.com//posts/2023-01-03-exploratory_analysis."
  },
  {
    "objectID": "posts/2022-12-30-promotion_prediction/index.html",
    "href": "posts/2022-12-30-promotion_prediction/index.html",
    "title": "Predicting Promotions Through Machine Learning",
    "section": "",
    "text": "Photo by Possessed Photography on Unsplash.\n\n\n\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dmckinnon2022,\n  author = {Adam D McKinnon},\n  title = {Predicting {Promotions} {Through} {Machine} {Learning}},\n  date = {2022-12-30},\n  url = {https://www.adam-d-mckinnon.com//posts/2022-12-30-promotion_prediction},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAdam D McKinnon. 2022. “Predicting Promotions Through Machine\nLearning.” December 30, 2022. https://www.adam-d-mckinnon.com//posts/2022-12-30-promotion_prediction."
  },
  {
    "objectID": "posts/2022-07-21-isolation_forests/index.html",
    "href": "posts/2022-07-21-isolation_forests/index.html",
    "title": "Automated assessment of employee data quality using machine learning",
    "section": "",
    "text": "Photo by Mika Baumeister on Unsplash.\n\n\n\n\n\nIntroduction\nThe topic of data quality is like that of I.T. services generally… you only ever hear about it when there’s a problem! There’s an implicit assumption among stakeholders receiving the findings of people analytics initiatives that your data is “good”. Failure to observe this assumption of high data quality can significantly (and rapidly) undermine the credibility of findings, irrespective of how small the data quality deviation!\nFrom an analytical perspective, the quality of your insights can potentially be limited by flawed data. As the saying goes “garbage in, garbage out”. Coupled with stakeholder expectations, it becomes increasingly important that organisations invest time and energy in the ongoing assessment and curation of quality data to maximise the influence of data driven decision making in organisations.\nAt the same time, monitoring data quality in HR can be immensely time consuming, expensive, simplistic in execution (i.e., simple evaluation criteria such as age ranges), highly repetitive, and utterly devoid of ANY professional enjoyment! To overcome these shortcomings, we have developed an automated, multi-dimensional and scalable approach to data quality evaluation using unsupervised machine learning—Isolation Forests.\n\n\nThe Process\nWe used Isolation Forests, an unsupervised machine learning approach to scan employee data for potentially anomalous[1] records.\nOur code can be viewed at this GitHub account, which followed the following process steps:\n\nIngested personnel data and loaded the appropriate libraries. In our example, we used the IBM HR Attrition dataset, then installed the H2o and Pandas libraries.\nDefined the dataset columns to include in the data quality assessment. Trained an Isolation Forest algorithm on the data. The Isolation Forest algorithm partitioned data through a forest of decision trees. Each split of the data was made randomly and the number of splits required to isolate a record indicated whether or not the record was considered anomalous. When a forest of random trees collectively produced shorter path lengths for particular records, they were highly likely to be considered anomalies.\nUsing the trained Isolation Forest model, we then predicted which records we believed to be anomalous. Of those records predicted to have data quality issues we then narrowed down to those with the highest likelihood of being anomalous using characteristics from the trained model.\nThe model has two levels of output interpretation:\n\nGlobal – which dataset columns are most often related to data quality errors. At best this is interesting in identifying potentially systemic errors, which may be a catalyst for more controlled data entry parameters.\nLocal – for any given record why is it deemed an anomaly. It is this level that is most valuable in directly resolving data quality issues, and therefore, was the focus of our approach.\n\nFor those records deemed highly anomalous (our subset), we then trained a simple Random Forest model to predict the anomaly flag(s). This process was repeated multiple times for each record to increase our certainty in identifying those variables contributing to its anomaly status. Note: We kept the model simple to make identification (and interpretation) of the combination of variables contributing to each records anomaly status easy to perform. In short, we wanted the output interpretable by a wide audience, not just those familiar with machine learning outputs.\nThe generated output (see excerpt of output in image below) has two fields: 1. A unique identifier, and 2. A list of variables contributing to each records anomaly status. The unique identifier, in our case the unique Employee Number taken from the original dataset, is critical to enabling identification and access to the original record that requires review. The second column has a ranked list (ranked from most important to least) showing the variables “collectively” contributing to the anomaly status. For example, when inspecting EmployeeNumber 58’s record we see a Monthly Income only four times their DailyRate (possibly incorrect), and that the individual has been with the company 2 years, had their last promotion 2 years ago, and has 2 years in their current role, which collectively cannot all be correct–the algorithm suggests reviewing YearsInCurrentRole.\n\n\n\n\n\n\nExample Output.\n\n\n\n\n\n\nConclusion\nUnsupervised Machine Learning algorithms such as Isolation Forests can be an excellent way of automating and scaling the review of data to monitor for quality concerns. The approach lends itself to those datasets that have a reasonable level of data quality and that are looking to make further improvements.\nThe major advantage of this approach is that the Isolation Forest can identify a record as anomalous, despite no one variable in the record being out of acceptable limits. Instead, the algorithm assesses the combination of multiple variables to determine if the combination makes it seem anomalous. This is like having human intelligence review each record quickly, at scale, and without destroying anyone’s job satisfaction!\nWe propose that this approach has the potential to significantly reduce time spent on direct data quality evaluations, which has considerable direct benefits (i.e., better quality data, more representative analyses and interpretation, etc.) as well as indirect benefits (i.e., time can be spent on other value-add initiatives that can only be done by humans!). This is particularly true for smaller teams, where the need to do more with less is greatest.\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{dmckinnon2022,\n  author = {Adam D McKinnon and Martha Curioni and Adam D McKinnon},\n  title = {Automated Assessment of Employee Data Quality Using Machine\n    Learning},\n  date = {2022-07-21},\n  url = {https://www.adam-d-mckinnon.com//posts/2022-07-21-isolation_forests},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAdam D McKinnon, Martha Curioni, and Adam D McKinnon. 2022.\n“Automated Assessment of Employee Data Quality Using Machine\nLearning.” July 21, 2022. https://www.adam-d-mckinnon.com//posts/2022-07-21-isolation_forests."
  }
]