{"title":"Predicting Promotions Through Machine Learning","markdown":{"yaml":{"title":"Predicting Promotions Through Machine Learning","date":"2023-05-02","description":"Building an XGBoost model in the Tidymodels ecosystem that predicts whether an employee should be promoted.","author":[{"name":"Adam D McKinnon"}],"categories":["Tidymodels","XGBoost","R","Machine Learning","Employee Promotions"],"image":"markus-spiske-QozzJpFZ2lg-unsplash.jpg","title-block-banner":true},"headingText":"Libraries","containsRefs":false,"markdown":"\n\n```{r header, echo=FALSE, code_folding = FALSE, fig.cap=\"Photo by [Possessed Photography](https://unsplash.com/@markusspiske) on [Unsplash](https://unsplash.com/).\", out.width = '100%'}\nknitr::include_graphics(\"markus-spiske-QozzJpFZ2lg-unsplash.jpg\")\n\n```\n\n<br>\n\nIn April 2023, I co-authored an [article](https://www.adam-d-mckinnon.com/posts/2023-04-05-using_ai_for_promotions/) with [Martha Curioni](https://www.linkedin.com/in/marthacurioni/) exploring the benefits of using AI to make better promotion decisions. The current article is intended to complement that article by providing a practical example of building an xgboost model in the Tidymodels ecosystem to predict promotions. By using the Tidymodels ecosystem, the current article also partners nicely with [another article](https://www.adam-d-mckinnon.com/posts/2023-04-16-assessing_bias_in_ml_models/) I wrote in April on the topic of assessing bias in Machine Learning (ML) models.\n\n<br>\n\n\nThe libraries used in this work were reasonably straightforward. The notable call outs are the following libraries:\n\n-   themis: enables a step in the pre-processing recipe that deals with unbalanced data;\n\n-   finetune: for performing the tuning process using the tune_race_anova function;\n\n-   cvms: provides a nice function for visualising a confusion matrix; and\n\n-   bundle: for saving the final model built. \n\n<br>\n\n```{r loading_libraries}\n\n# data manipulation\nlibrary(readxl)\nlibrary(tidyverse)\n\n# modelling\nlibrary(tidymodels)\nlibrary(themis)\nlibrary(finetune)\nlibrary(bundle)\nlibrary(cvms)\nlibrary(bundle)\n\n# Processing power\nlibrary(doParallel)\nlibrary(parallelly)\n\n# Visualisation\nlibrary(plotly)\n\ntidymodels_prefer()\n\n```\n\n<br>\n\n# Data\n\nThe data is a fictitious dataset of employee promotions. The target variable-promotions-is characterised by two mutually exclusive outcomes: 1. promoted (n=342) or 2. not promoted (n=539). The promoted outcome represents 39% of the dataset, reflecting a modest class imbalance.\n\n<br>\n\n```{r loading_data}\n\n# Load Data ----\npromotions_tbl <- readxl::read_excel(path = \"2022_12_15_promotions.xlsx\")\n\n\npromotions_tbl <- promotions_tbl |> \n    mutate(promoted  = forcats::as_factor(promoted) %>% forcats::fct_relevel(\"promoted\", \"not promoted\")) |>  \n    mutate_at(.vars = c(\"gender\", \"work_site\", \"management_level\"), .funs = ~ forcats::as_factor(.))\n\n\n```\n\n<br>\n\n# Building an ML Model\n\n### 1. Splitting the data\n\nThe data is split into the train and test datasets, ensuring the promoted cases are proportionally distributed across the two datasets (i.e., the strata). The data is then bootstrapped into 75 different datasets for the model tuning process. Bootstrapping is the process of resampling a single dataset to create many datasets. In bootstrapping, it is possible for a single case to be present in more than one of the resampled datasets. Bootstrapping was employed as the original dataset was not large (n=881), and means we can \"spend\" our data more effectively for tuning.\n\n<br>\n\n```{r splitting_data}\n\n# Spending the dataset ----\n\nset.seed(836)\npromotion_split     <- initial_split(promotions_tbl, strata = promoted)\npromotion_train_tbl <- training(promotion_split)\npromotion_test_tbl  <- testing(promotion_split)\n\n\nset.seed(234)\npromotion_folds <- bootstraps(promotion_train_tbl, \n                              times = 75, # default is 25 - inflated to accommodate racing method of tuning \n                              strata = promoted)\n\n# check the promotion_folds \n# promotion_folds\n\n\n\n```\n\n<br>\n\n### 2. Pre-processing the data\n\nThe recipe identifies the target variable and dataset, and then performs four pre-processing steps. These steps include:\n\n1.  Update the role of the employee id variable. This variable could have been removed, however, retaining the id can help in potentially identifying cases should the need later arise.\n\n2.  Turn all variables into dummy variables (i.e., 0 or 1) for each of the categorical variables (e.g., gender, work site, management level).\n\n3.  Remove any variables that contains only a single variable, and thereby offers no predictive value to the model. While not relevant in this dataset, the inclusion could be perceived as good discipline.\n\n4.  Generate synthetic data by Randomly Over Sampling Examples (ROSE). This was done as the promoted outcome was fewer in number than not being promoted. ROSE is but one of several techniques for addressing class imbalance in models.\n\n<br>\n\n```{r data_preprocessing}\n\n# Data Pre-processing ----\nxgboost_recipe <- \n    recipe(formula = promoted ~ ., data = promotion_train_tbl) |>  \n    recipes::update_role(employee_id, new_role = \"id\") |>  \n    step_dummy(all_nominal_predictors(), one_hot = TRUE) |>  \n    step_zv(all_predictors()) |> \n    step_rose(promoted)\n\n\n\n\n# check the recipe\n# xgboost_recipe\n\n```\n\n<br>\n\n### 3. Create a model specification\n\nThe model specification is fairly standard. With the exception of the number of trees, all other parameters are tuned to find the best combination.\n\n<br>\n\n```{r model_spec}\n\n# Model Set-up ----\nxgboost_spec <- \n    boost_tree(trees = 1000, \n               tree_depth = tune(),\n               min_n = tune(),\n               mtry = tune(),\n               learn_rate = tune()) |>  \n    set_engine(\"xgboost\") |>  \n    set_mode(\"classification\")\n\n\n# check the model specification\n# xgboost_spec\n\n```\n\n<br>\n\n### 4. Workflow setup\n\nThe workflow creation is a simply process that involves adding both the recipe and model specification to a workflow object.\n\n<br>\n\n```{r workflow_setup}\n\n\n# Workflow setup\nxgboost_workflow <- \n    workflow() |> \n    add_recipe(xgboost_recipe) |>  \n    add_model(xgboost_spec) \n\n# Check the workflow\n# xgboost_workflow\n\n\n```\n\n<br>\n\n### 5. Tuning the model\n\nThree key activities occur when tuning the model. These are:\n\n1.  Specifying the metrics that will be used to assess the model. In practice only one metric is used in the 'tune_race_anova' function, which is always the first specified in the 'metric_set' function. If a metric is not defined the defaults are either accuracy of RMSE, depending upon the model type.\n\n2.  The next step is to enable parallel processing, using the 'availableCores' function, to expedite the tuning process. Using the availableCores function strikes me as a more effective/accurate method of specifying the number of processors to employ (i.e., better than registerDoParallel -\\> detectCores).\n\n3.  Finally, we define the 'tune_race_anova' function, specifying the workflow, resamples, and metrics. It is important to save the predictions from the tuning process.\n\n<br>\n\n```{r model_tuning}\n\n# specify the metrics of interest\n# NOTE: The first metric listed will be used for tuning\npromotion_metrics <- metric_set(\n                            roc_auc, \n                            accuracy, \n                            sensitivity, \n                            specificity\n                            )\n\n\n# enable parallel processing based on the number of available cores\ndoParallel::registerDoParallel(cores = parallelly::availableCores())\n\n\nset.seed(826)\nracing_resamples <- finetune::tune_race_anova(\n    xgboost_workflow,\n    resamples = promotion_folds,\n    grid = 100, # cast a wide grid to optimise the results -\n                # works best with many resamples - set earlier to 75\n    metrics = promotion_metrics,\n    control = control_race(\n        verbose_elim = TRUE,\n        save_pred    = TRUE\n        )\n)\n\n\n# racing_resamples\n\n\n\n```\n\n<br>\n\n### 6. Assess model performance\n\nHere we look at the results of the model tuning process in two ways:\n\n1.  The model metrics for the combination(s) that \"won\" the anova race; and\n\n2.  The plot of the tuning process. The plot shows the number of model combinations that were dropped early in the process (i.e., a considerable time saving) to reach the combination(s) that won the process. The plot nicely illustrates that this approach can be an efficient way of testing multiple model parameters quickly and effectively!\n\n<br>\n\n```{r assess_model}\n\nfirst_model_metrics_tbl <- collect_metrics(racing_resamples)\ntuning_plot <- plotly_build(plot_race(racing_resamples))\n\nxaringanExtra::use_panelset()\n\n```\n\n::: panelset\n::: panel\n[Promotion Metrics]{.panel-name}\n\n```{r echo=FALSE, code_folding = FALSE}\n\nfirst_model_metrics_tbl |>  gt::gt()\n\n```\n:::\n\n::: panel\n[Model Tuning Visualisation]{.panel-name}\n\n```{r echo=FALSE, code_folding = FALSE}\n\ntuning_plot\n\n```\n:::\n:::\n\n<br>\n<br>\n\n### 7. Finalise the workflow\n\nFinalising the workflow involves two steps:\n\n1.  Selecting the best performing model, in this case using the ROC value (which can be plotted if desired). The ROC metric lends itself to measuing the performance of classification models. We can see how well the model performs on ROC and accuracy.\n\n2.  Extracting the workflow so that we can make some predictions and assess their performance with the confusion matrix.\n\n<br>\n\n```{r finalise_workflow}\n\n# last_fit_xgboost_workflow\nlast_fit_xgboost_workflow <- xgboost_workflow |> \n    finalize_workflow(select_best(racing_resamples, \"roc_auc\")) |> \n    last_fit(promotion_split)\n\n# test the fit\nfinal_model_workflow_metrics <- collect_metrics(last_fit_xgboost_workflow) |> gt::gt()\n\n# extract the model workflow for further testing & saving\nfinal_model_workflow <- last_fit_xgboost_workflow |> \n    extract_workflow()\n\n# display the metrics - places at the end of this code chunk for a cleaner presentation on the article\nfinal_model_workflow_metrics\n\n```\n\n<br>\n\n### 8. Re-assess model performance\n\nThe final model assessment is performed by making predictions on data the model has not previously seen (i.e. out test dataset). We begin by making predictions on the test dataset, and appending those predictions to the dataset. Using the actual and predicted values we can then assess the model performance using the confusion matrix.\n\nThe confusion matrix provides an overview of our success with the model, comparing the actual promotion values (i.e., Target) with those predicted. The values in the respective quadrants reflect the number of cases that fell into each category. In addition, the subscript sized values display the proportions corresponding to the direction of interpretation (i.e., looking at the predictions or targets). A detailed guide to interpretation of confusion matrices can be found [here](https://www.analyticsvidhya.com/blog/2021/05/in-depth-understanding-of-confusion-matrix/).\n\nInterestingly, when the process was run without addressing the class imbalance in the recipe the ability to predict the minority class (i.e., being promoted or a True Positive) decreased by \\~12%. However, this increase came at the expense of the ability to accurately predict not being promoted (i.e., the True Negative--bottom right of confusion matrix), which decreased by \\~9%.\n\n<br>\n\n```{r predictions}\n\n# test the model\npred_test <- final_model_workflow |> \n    predict(promotion_test_tbl) |> \n    bind_cols(promotion_test_tbl)\n\n# Visualise the performance using a confusion matrix\npred_test |> \n    # retrieve the relevant variables\n    select(.pred_class, promoted) |> \n    # convert the text to numeric format\n    mutate_all(~if_else(.x == \"promoted\", 1, 0)) |> \n    # aggregate into a table and then convert the table to tibble\n    table() |> \n    tibble::as_tibble() |> \n    # plot the confusion matrix\n    cvms::plot_confusion_matrix(\n        target_col     = \"promoted\",\n        prediction_col = \".pred_class\",\n        counts_col     = \"n\",\n        palette        = \"Greens\",\n        add_normalized = FALSE # this removes the normalised count % from the middle of each square - easier to reading the interpretation\n    )\n    \n\n```\n\n<br>\n\n# Save the model\n\nThe model is saved out using the bundle library, which provides a simple and consistent way to prepare R model objects to be saved and re-loaded. This affords users a time saving when deploying workflows.\n\n<br>\n\n```{r save_model}\n\n# save the model for future use \nmodel_bundle <- bundle::bundle(final_model_workflow)\nreadr::write_rds(model_bundle, file = \"model_bundle.rds\")\n\n```\n\n<br>\n\n# Conclusion\n\nThe above walk through details the steps for building and tuning an xgboost model that predicts promotions in an employee dataset. The article walks through some interesting nuances such as ROSE to address class imbalance, racing model tuning, a more detailed confusion matrix using the cvms package, and saving models using the bundle package.\n\nHappy coding!\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc-depth":3,"toc":true,"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.313","editor":"visual","theme":["lux","../../theme.scss"],"title-block-banner":true,"title-block-banner-color":"white","license":"CC BY","toc-title":"Table of contents","toc-location":"left","citation":true,"title":"Predicting Promotions Through Machine Learning","date":"2023-05-02","description":"Building an XGBoost model in the Tidymodels ecosystem that predicts whether an employee should be promoted.","author":[{"name":"Adam D McKinnon"}],"categories":["Tidymodels","XGBoost","R","Machine Learning","Employee Promotions"],"image":"markus-spiske-QozzJpFZ2lg-unsplash.jpg"},"extensions":{"book":{"multiFile":true}}}}}