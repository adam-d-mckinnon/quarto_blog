---
title: 'Predicting Wine Ratings Using Reviews'
date: 2023-08-19
description: "Using a mix of quantitative and qualitative data to predict wine ratings globally. This approach demonstrates the utility of text based data in ML models for predicting outcomes of interest. "
author: 
    - name: Adam D McKinnon
categories: [AI, Text, Wine Reviews]
image: "hermes-rivera-aK6WGqxyHFw-unsplash.jpg"
title-block-banner: true
draft: true
---

```{r header, echo=FALSE, code_folding = FALSE, fig.cap="[Photo by Hermes Riveria on Unsplash](https://unsplash.com/@hermez777).",out.width = '100%'}
knitr::include_graphics("hermes-rivera-aK6WGqxyHFw-unsplash.jpg")
  

```

<br>

## Introduction

```{r libraries}

# data manipulation & exploration
library(tidyverse)
library(DataExplorer)
library(tidytext)
library(udpipe)
library(BTM)


# modelling
library(tidymodels)
library(textrecipes)
library(agua)

# Processing power
library(doParallel)
library(parallelly)

# visualisations
library(igraph)
library(ggraph)


```

```{r data_cleaning}

# Data was downloaded here: https://www.kaggle.com/datasets/manyregression/updated-wine-enthusiast-review
original_tbl <- readr::read_csv(file = "winemag-data-2017-2020.csv") |> 
    
    # clean the variable names
    janitor::clean_names() 


# for modelling we will use the following variables
vars_to_model <- c("variety", "vintage", 
                  "country", "province",
                  "title", # retain for identification purposes
                  "points", "price", "taster_name", "description")


# data exploration
# original_tbl |>
#     DataExplorer::create_report()


cleaned_tbl <- 
original_tbl |> 
    
    # select the variables of interest defined above
    dplyr::select(one_of(vars_to_model)) |> 
    # convert the following variables into factors 
    dplyr::mutate_at(c("country", "vintage", "variety", "province"), ~forcats::as_factor(.)) |> 
    # drop any missing data
    tidyr::drop_na(country, province, taster_name, price) |> 
    # retain only those enties that have a unique description
    dplyr::distinct(description, .keep_all = TRUE)
    

```

```{r filtering_dataset}

# cleaned_tbl |> 
#     DataExplorer::create_report()


vintages <- 
cleaned_tbl |> 
    dplyr::count(vintage) |> 
    dplyr::arrange(desc(n)) |> 
    dplyr::filter(n > 5000) |> 
    dplyr::pull(vintage)


cleaned_vintages_tbl <- 
    cleaned_tbl |> 
    dplyr::filter(vintage %in% vintages)

cleaned_vintages_tbl |> 
    dplyr::count(vintage) |> 
    dplyr::arrange(desc(n))


unacceptable_whites <- c("Chardonnay", "Riesling", "RosÃ©", "Sauvignon Blanc")

acceptable_reds <- 
cleaned_vintages_tbl |> 
    dplyr::count(variety) |> 
    dplyr::arrange(desc(n)) |> 
    dplyr::filter(n > 1000) |> 
    dplyr::filter(!variety %in% unacceptable_whites) |> 
    dplyr::pull(variety)


cleaned_red_vintages_tbl <- cleaned_vintages_tbl |> 
    dplyr::filter(variety %in% acceptable_reds)


```

```{r data_exploration}

# # ud_model <- udpipe_download_model(language = "english")
# ud_model <- udpipe_load_model(file = "english-ewt-ud-2.5-191206.udpipe")
# 
# 
# # create doc_id and convert to character to enable joining with the
# # output of udpipe_annotate, which produces a character doc_id output
cleaned_identifier_tbl <- cleaned_red_vintages_tbl |>
    dplyr::mutate(doc_id = dplyr::row_number() |> as.character())



# 
# 
# # annotate the text using udpipe and save as a tibble
# annotated_text <- udpipe::udpipe_annotate(
#                                         ud_model,
#                                         x      = cleaned_identifier_tbl$description,
#                                         doc_id = cleaned_identifier_tbl$doc_id) |>
#                   tibble::as_tibble()
# 
# 
# # write the annotation to file for future reference
# annotated_text |>
#     readr::write_rds(file = "annotated_text_tbl.rds")
# 

# read the annotated text file
annotated_text_tbl <- readr::read_rds(file = "annotated_text_tbl.rds")


```

```{r visualise_annotated_text}


cleaned_annotated_text_tbl <- annotated_text_tbl |> 
                              dplyr::filter(upos %in% c("ADJ", "NOUN")) |> 
                                
                              # turn the token and lemma variables to lower case
                              dplyr::mutate_at(dplyr::vars(token, lemma), ~ stringr::str_to_lower(.)) |> 
                                
                              # join the points variable (i.e., the wine rating)
                              dplyr::left_join(cleaned_identifier_tbl, by = c("doc_id" = "doc_id"))




words_for_plot_tbl <- cleaned_annotated_text_tbl |> 
    # group by the "word" from the description and see the frequency and the 
    # mean score it was associated with.
    dplyr::group_by(lemma) |> 
    dplyr::summarise(
        n = n(),
        rating = mean(points, na.rm = TRUE) |> round(digits = 2)
        ) |> 
    
    # only show words associated with an average rating of 90 or more
    # dplyr::filter(rating >= 90) |> 
    
    # create a detailed description for plotting
    dplyr::mutate(plot_description = stringr::str_glue(
        "Descriptor: {lemma}
        Frequency: {n}
        Average Rating: {rating}
        "
    )) 



word_rating_plot <-
    words_for_plot_tbl |> 
    arrange(desc(n), desc(rating)) |> 
    dplyr::select(lemma, rating, n, plot_description) |>
    dplyr::slice(1:150) |> 
    ggplot(aes(x = n, y = rating, text = plot_description)) +
    geom_hline(
        yintercept = mean(cleaned_tbl$points), lty = 2,
        color = "red", size = 0.5
        ) +
    geom_jitter(alpha = 0.7) +
    geom_text(aes(label = lemma),
              vjust = "top", hjust = "left"
              ) +
  scale_x_log10()

plotly::ggplotly(word_rating_plot, tooltip = "text")


```

```{r text_network}


biterms <- data.table::as.data.table(annotated_text_tbl)


# 
# cooc_tbl <- cooccurrence(x = cleaned_annotated_text_dt, 
#                      term = "lemma", 
#                      group = c("doc_id", "paragraph_id", "sentence_id")) |> 
#     
#             tibble::as_tibble() |> 
#             dplyr::filter(!term1 == "wine") |> 
#             dplyr::filter(!term2 == "wine")
# 


## Get cooccurrences of nouns / adjectives and proper nouns
# biterms <- data.table::as.data.table(annotated_text_dt)
biterms <- biterms[, cooccurrence(x = lemma, 
                                  relevant = upos %in% c("NOUN", "PROPN", "ADJ"),
                                  skipgram = 2), 
                   by = list(doc_id)]



plt <- textplot::textplot_cooccurrence(
                                    biterms,
                                    title = "Nouns + Adjectives",
                                    top_n = 1175,
                                    vertex_color = "orange", 
                                    edge_color = "black",
                                    fontface = "bold")

plt
plotly::plotly_build(plt)



## Build the model
set.seed(123456)
x     <- annotated_text_tbl |> 
    dplyr::filter(upos %in% c("NOUN", "PROPN", "ADJ")) |> 
    dplyr::select(doc_id, lemma)

model <- BTM::BTM(x, k = 10, beta = 0.01, iter = 200, background = TRUE, 
             biterms = biterms, trace = 100)


plt <- plot(model, title = "Biterm topic model", subtitle = "Topics 2 to 10", which = 2:10, top_n = 10)
plt


topicterms <- terms(model, top_n = 15)
topicterms


library(textplot)
library(ggraph)
library(concaveman)
plot(model)



cooc_tbl |> view()





wordnetwork <- head(biterms, 500)
wordnetwork <- biterms
# wordnetwork <- cooc_tbl |> filter(cooc>300) 
wordnetwork <- igraph::graph_from_data_frame(wordnetwork, directed = FALSE)

l <- layout_with_fr(wordnetwork)
plot(wordnetwork, rescale=F, layout=l*0.4)


g4s <- simplify(wordnetwork, remove.multiple = T, remove.loops = T, 
                 edge.attr.comb=c(weight="sum", type="ignore") )

plot(g4s, vertex.label.dist=1.5)




# Find group membership
wt <- igraph::cluster_leiden(wordnetwork)
members <- membership(wt)

# Convert to object suitable for networkD3
karate_d3 <- igraph_to_networkD3(wordnetwork, group = members)

# Create force directed network plot
forceNetwork(Links = karate_d3$links, Nodes = karate_d3$nodes,
             Source = 'source', Target = 'target', NodeID = 'name',
             Group = 'group')









set.seed(2020)
ggraph(wordnetwork, layout = "fr") +
    geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "pink") +
    geom_node_point(color = "darkblue", size = 2, alpha = .3) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1, size = 3) +
    theme_graph(base_family = "Arial Narrow") +
    theme(legend.position = "none") +
    labs(title = "Cooccurrences within sentence", subtitle = "Nouns & Adjective")


```

```{r}
library(visNetwork)
visNetwork::visIgraph(wordnetwork) |> 
    visNodes(
        shape = "circle", 
        size = 5,
        color = list(background = "lightblue"), 
        font = list(color = "black", size = 35),
        shapeProperties = list(useBorderWithImage = TRUE)
        
        ) |> 
    visEdges(
        arrows = 'none', 
        color = "grey"
        
        ) |> 
    visOptions(
        highlightNearest = list(enabled = T, 
                                degree = 1,
                                hover = T),
        width = "100%",
        height = "100%"
        
        ) |> 
     visIgraphLayout(layout = "layout.star")
    # visIgraphLayout(layout = "layout_on_sphere")
    





```

```{r}

library(networkD3)
# Extract nodes
nodes <- data.frame(name=V(wordnetwork)$name)

# Extract edges
edges <- get.data.frame(wordnetwork, what="edges")[,1:2]

edges$from <- match(edges$from, nodes$name) - 1  # Subtracting 1 to make indices start from 0
edges$to <- match(edges$to, nodes$name) - 1


edges$from_name <- match(edges$from_name, nodes$name) -1

net <- simpleNetwork(edges)
net

```

```{r data_budget}

set.seed(385)
wine_split <- initial_split(cleaned_tbl)
wine_train_tbl <- training(wine_split)
wine_test_tbl <- testing(wine_split)

set.seed(679)
wine_folds <- vfold_cv(wine_train_tbl)
wine_folds




```

```{r recipe}

wine_recipe <- 
    recipes::recipe(points ~ description, data = wine_train_tbl) |> 
    # recipes::update_role(title, new_role = "id") |> # keep the title of the wine for identification purposes only
    recipes::step_log(price) |> 
    recipes::step_other(country, variety, vintage, province, threshold = 0.05) |> 
    recipes::step_dummy(country, variety, vintage, province) |> 
    textrecipes::step_tokenize(description, engine = "spacyr") |>
    textrecipes::step_stopwords(description) |> 
    textrecipes::step_tokenfilter(description, mint_times = 100, max_tokens = 5000) |> 
    textrecipes::step_lemma(description) |> 
    textrecipes::step_tfidf(description) |> 
    textrecipes::step_texthash(taster_name) |> 
    step_normalize(points, price)
    


output <- prep(wine_recipe) |> bake(new_data = NULL)
unlist(output)

    
?step_tokenize()    
    
    


```
