---
title: 'Using ML to Predict Remuneration Levels'
date: 2023-05-19
description: "Using the TidyModels ecosystem to apply and tune multiple models to determine optimal performance. This approach could be used, coupling market data and existing employee pay levels, to remunerate staff fairly and effectively."
author: 
    - name: Adam D McKinnon
categories: [AI, Bias, Promotions, People Analytics]
image: "sasun-bughdaryan-GQ5uX_BlfmY-unsplash.jpg"
title-block-banner: true
draft: false
---

```{r header, echo=FALSE, code_folding = FALSE, fig.cap="[Photo by Sasun Bughdaryan on Unsplash](https://unsplash.com/fr/@sasun1990).",out.width = '100%'}
knitr::include_graphics("sasun-bughdaryan-GQ5uX_BlfmY-unsplash.jpg")
  
```

<br>

## Introduction

### Libraries

<br>

```{r libraries}

# data manipulation
library(tidyverse)

# modelling
library(tidymodels)
library(finetune)
library(rules)

# model explaining
library(DALEX) # model explainer
library(DALEXtra) # model explainer with tidymodels functionality
library(modelStudio)

# Processing power
library(doParallel)
library(parallelly)

# Visualisation
library(plotly)

tidymodels_prefer()


```

<br>

### Data

<br>

```{r data}

original_tbl <- readr::read_csv(file = "dataset-37830.csv") |> 
    
    # clean the variable names
    janitor::clean_names() |> 
    
    # convert all character variables to factors
    dplyr::mutate_if(is.character, ~forcats::as_factor(.)) |> 
    
    # convert the year variable to a factor
    dplyr::mutate(year = forcats::as_factor(year)) |> 
    
    dplyr::select(-wage)


```

<br>

### Data Splits

<br>

```{r data_splits}

# Spending the dataset ----
set.seed(836)
pay_split     <- initial_split(original_tbl)
pay_train_tbl <- training(pay_split)
pay_test_tbl  <- testing(pay_split)


set.seed(234)
pay_folds <- 
   bootstraps(pay_train_tbl)

# check the pay_folds 
# pay_folds

```

<br>

### Receipe

<br>

```{r model_recipes}

normalized_rec <- 
    recipe(logwage ~ ., data = pay_train_tbl) %>% 
    step_zv(all_predictors()) |> 
    step_dummy(all_nominal_predictors(), one_hot = TRUE) |> 
    step_normalize(age)
    

```

<br>

### Model Specifications

<br>

```{r model_specs}

rf_spec <- 
   rand_forest(
       mtry  = tune(), 
       min_n = tune(), 
       trees = 1000) |> 
   set_engine("ranger") |> 
   set_mode("regression")


xgb_spec <- 
   boost_tree(
       tree_depth     = tune(), 
       learn_rate     = tune(), 
       loss_reduction = tune(),
       min_n          = tune(), 
       sample_size    = tune(), 
       trees          = tune()
       ) |> 
   set_engine("xgboost") |> 
   set_mode("regression")


cubist_spec <-
   cubist_rules(
       committees = tune(), 
       neighbors  = tune()
       ) |> 
   set_engine("Cubist")


knn_spec <-
   nearest_neighbor(
       neighbors   = tune(), 
       dist_power  = tune(), 
       weight_func = tune()
       ) |> 
   set_engine("kknn") |> 
   set_mode("regression")


linear_reg_spec <-
   linear_reg(
       penalty = tune(), 
       mixture = tune()
       ) |> 
   set_engine("glmnet")


```

<br>

### Workflowsets

<br>

```{r workflowsets}


normalised_wf <-
    workflow_set(
        preproc = list(normalized_rec),
        models = list(
            rf_spec, 
            xgb_spec, 
            cubist_spec, 
            knn_spec, 
            linear_reg_spec
            )
  ) 
 

normalised_wf <- normalised_wf |>  
     mutate(wflow_id = gsub("(recipe_)", "", wflow_id))



```

<br>

### Model Tuning

<br>

```{r model_tuning}

race_ctrl <-
   control_race(
      save_pred     = TRUE,
      parallel_over = "everything",
      save_workflow = TRUE
   )



doParallel::registerDoParallel(cores = parallelly::availableCores())
 
fit_wf <- normalised_wf %>%  
  workflow_map(
      "tune_race_anova",
      seed = 44, 
      grid = 25,           ## parameters to pass to tune grid
      resamples = pay_folds,
      control = race_ctrl
  )

doParallel::stopImplicitCluster()


```

<br>

### Assess Model Performance

<br>

```{r model_performance}

model_performance_plot <- 
    autoplot(
        fit_wf,
        rank_metric = "rmse",  
        metric      = "rmse",
        select_best = TRUE
        ) +
    geom_text(aes(y = mean - .005, label = wflow_id), hjust = 1) +
    lims(y = c(0.265, 0.31)) +
    theme(legend.position = "none")


plotly::plotly_build(model_performance_plot)


```

<br>

### Finalise Workflow

<br>

```{r model_fit}

best_results <- 
   fit_wf %>% 
   extract_workflow_set_result("cubist_rules") %>% 
   select_best(metric = "rmse")

best_results


cubist_fit <- 
   fit_wf %>% 
   extract_workflow("cubist_rules") %>% 
   finalize_workflow(best_results) %>% 
   last_fit(split = pay_split)

collect_metrics(cubist_fit)


final_fitted <- cubist_fit |> extract_workflow()
predict(final_fitted, pay_test_tbl[10:12, ])


```

<br>

### Re-assess Final Model

<br>

```{r model_fit_performance}

predictions_plot <- 
    cubist_fit |>
    collect_predictions() |>
    mutate(
        `Actual Wage` = exp(logwage) |> formattable::currency(),
        `Predicted Wage` = exp(.pred) |> formattable::currency()
        ) |> 
    
    ggplot(aes(x = `Actual Wage`, y = `Predicted Wage`)) + 
    geom_abline(color = "red", lty = 10) + 
    geom_point(alpha = 0.5) + 
    coord_obs_pred() + 
    labs(x = "Actual", y = "Predicted") +
    coord_cartesian(xlim =c(0, 350), ylim = c(50, 200))


plotly::plotly_build(predictions_plot)

```

<br>

```{r explainer}


pay_explainer <- DALEXtra::explain_tidymodels(
    final_fitted,
    data    = pay_test_tbl |> select(-logwage),
    y       = pay_test_tbl$logwage,
    verbose = FALSE

)


model_performance(pay_explainer)


# pick observations
new_observation <- pay_test_tbl[1:2,]
rownames(new_observation) <- c("id1", "id2")


# make a studio for the model
modelStudio_obj <- modelStudio::modelStudio(pay_explainer, new_observation)


```

```{r modelstudio_output, include=FALSE, out.width = '100%'}

knitr::include_url(modelStudio_obj)
# <iframe width="100%" height="400"
#   src="modelStudio_obj"
#   frameborder="0" 
#   allowfullscreen></iframe>


```

## Save the model

The model is saved out using the bundle library, which provides a simple and consistent way to prepare R model objects to be saved and re-loaded. This affords users a time saving when saving, sharing and deploying workflows.

<br>

```{r save_model}

# save the model for future use 
model_bundle <- bundle::bundle(final_fitted)
readr::write_rds(model_bundle, file = "model_bundle.rds")

```

<br>

# Conclusion
